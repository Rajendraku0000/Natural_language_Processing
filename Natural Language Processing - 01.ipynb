{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a101a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afc08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\saurabh\\\\Desktop\\\\pyth\\\\IMDB DataSet.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa6d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff130c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b91ce",
   "metadata": {},
   "source": [
    "# step1  Lowercasing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb57517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392da877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I want to convert all movies review then  \n",
    "\n",
    "df['review'] = df['review'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d486843e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6fb51",
   "metadata": {},
   "source": [
    "# step-2  Remove HTML Tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d639b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'' , text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21cfdf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<html><body><p> Movie1 </p><p> Click here to <a href = 'http://google.com'>download</a></p> \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51e283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Movie1  Click here to download '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5887ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we remove tags from IMDB Datasets  \n",
    "\n",
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f87b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54af0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to  remove urls from text then \n",
    "\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'' , text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124c6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.deture.com/delta/note1234acc'\n",
    "\n",
    "text2 = 'Check  out my notebook http://www.deture.com/delta/note1234acc'\n",
    "\n",
    "text3 = 'Google search here www.google.com'\n",
    "\n",
    "text4 = 'For notebook click https://www.deture.com/delta/note1234acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40c4eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google search here '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0dc7b",
   "metadata": {},
   "source": [
    "# step-4   Remove Punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cde8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import time\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d8e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "125167c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char , '')\n",
    "    return text     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0f0245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'string. With. Punctuation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbca1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With Punctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 = time.time() - start \n",
    "print(time1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b078b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have large amount of data then we use \n",
    "\n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('' , '' , exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e267b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With Punctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc1(text))\n",
    "time2 = time.time() - start \n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68aed686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\saurabh\\\\Desktop\\\\pyth\\\\twitter_sentiment_analysis.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8a18e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid Ã°ÂŸÂ˜Â˜ #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1      31964   @user #white #supremacists want everyone to s...\n",
       "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid Ã°ÂŸÂ˜Â˜ #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74d303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec1f43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('' , '' , exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "576fb068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1dc8401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>user white supremacists want everyone to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd bihday to my amazing hilarious nephew el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory leftright polarisation trump u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid Ã°ÂŸÂ˜Â˜ hairflip neverread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>hillary campaigned today in ohioomg amp used w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song so glad free download  shoegaze newm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  studiolife aislife requires passion dedication...\n",
       "1      31964   user white supremacists want everyone to see ...\n",
       "2      31965  safe ways to heal your acne    altwaystoheal h...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd bihday to my amazing hilarious nephew el...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory leftright polarisation trump u...\n",
       "17193  49156  feeling like a mermaid Ã°ÂŸÂ˜Â˜ hairflip neverread...\n",
       "17194  49157  hillary campaigned today in ohioomg amp used w...\n",
       "17195  49158  happy at work conference right mindset leads t...\n",
       "17196  49159  my   song so glad free download  shoegaze newm...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f35ffa",
   "metadata": {},
   "source": [
    "# step-5 Chatword Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66889259",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {'u2' : 'you too' , 'BBL':'Be Back Later' , 'GAL':'Get A Life'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab5734e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u2': 'you too', 'BBL': 'Be Back Later', 'GAL': 'Get A Life'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ea8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words :\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else :\n",
    "            new_text.append(w) \n",
    "            \n",
    "    return \"\".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d84011a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get A Life'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation('GAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7010f",
   "metadata": {},
   "source": [
    "# step-6  Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c16f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e3a8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55769a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = \"ceertain conditionas seveal ggenerations aree modified in the saame maner.\"\n",
    "\n",
    "textBlb = TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc4845",
   "metadata": {},
   "source": [
    "# step-7  Removing StepWords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105469a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e12f3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m STOPWORDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed4e0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c06daae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probablyall-timefavoritemovie,storyselflessness,sacrificededicationnoblecause.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually work \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        \n",
    "        if word in set(stopwords.words('english')):\n",
    "            new_text.append('')\n",
    "        \n",
    "        else :\n",
    "            new_text.append(word)\n",
    "            \n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \"\".join(x)\n",
    "        \n",
    "    \n",
    "remove_stopwords('probably my all-time favorite movie , a story of selflessness , sacrifice and dedication to a noble cause.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604bc5a",
   "metadata": {},
   "source": [
    "# Handling Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f306c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"   #emotions\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"   #symbols & pictographs \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"   #transport & map symbols \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"   # flags(ioS) \n",
    "                               u\"/U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"] +\" , flags = re.UNICODE)\n",
    "    return emoji_pattern.sub(r'' , text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f717cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62ef947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :face_blowing_a_kiss: ,:crying_face: , :crossed_fingers:   \n"
     ]
    }
   ],
   "source": [
    "import emoji \n",
    "print(emoji.demojize('Python is ðŸ˜˜ ,ðŸ˜¢ , ðŸ¤ž   '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4ff6b",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f2ac5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prefix - character(s) at the begining  = $(\" .)\n",
    "\n",
    "# 2. suffix - character(s) at the end = km).!\" \n",
    "\n",
    "# 3. Infix - character(s)  in between = --/...  \n",
    "\n",
    "# 4. Exception - Special-case rule to split a string into several tokens or\n",
    "# prevent a token from being split when punctuation rules are applied . = let's  U.s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2e237f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach the tokenization  using the split function\n",
    "\n",
    "# 1. word tokenization \n",
    "\n",
    "sent1 = \"I am going to delhi\" \n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4993deec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi ',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization \n",
    "sent2 = \"I am going to delhi . I will stay there for 3 days. Let\\'s hope the trip to be great\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27e869c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function \n",
    "sent3 = \"I am going to delhi!\" \n",
    "sent3.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57294dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the sent3 problem , there is seeing that ! is include with delhi . so , we have to remove it by regular expression . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb89f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am going to delhi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sent3 = \"I am going to delhi\"\n",
    "tokens = re.findall(\"[\\w']+\" , sent3)\n",
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebde5e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Lorem Ispum is simply dummy test of the printing industry',\n",
       " '\\nlorem this is my book , \\ni see a point ',\n",
       " '']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''' Lorem Ispum is simply dummy test of the printing industry?\n",
    "lorem this is my book , \n",
    "i see a point .'''\n",
    "\n",
    "sentences = re.compile('[.!?]').split(text)\n",
    "sentences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc480c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here , we saw that some issue wew on split function and regular expression . So , we have to use libraries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91c9df",
   "metadata": {},
   "source": [
    "# 1. NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0188c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b88bb830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14dc0fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"I am going to visit delhi!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a6a8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = 'I have a Ph.D. in A.I.' \n",
    "sent3 = \"We 're here to help! mail us at nks@gmail.com \" \n",
    "sent4 = 'A 5km ride cost $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29811911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D.', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae7fc776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'nks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "075fc3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e8e78",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71cc0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Inflection ==> \"In grammar , inflection is the modification of a word \n",
    "# to express different grametical categories such as tense , case , voice , aspect , person , number , gender and mood .\"\n",
    "\n",
    "\n",
    "# 2. Stemming ==> Stemming is the process of reducing inflection in words to their root forms\n",
    "# such as mapping a group of words to the same stem even if the  stem itself is not valid word in the language . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afb8c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "522f8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11ea2f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\" \n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92d4096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favourite movie a story of selflessness sacrifice and dedication.\n"
     ]
    }
   ],
   "source": [
    "# stemming mapping a group pf words to the same stem even if the stem itself is not valid word in language .So , this is the big issu of stemming . \n",
    "\n",
    "text = 'probably my alltime favourite movie a story of selflessness sacrifice and dedication.'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93804418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my alltim favourit movi a stori of selfless sacrific and dedication.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2c36419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So , we have to use lemmatization instead of stemming .\n",
    "\n",
    "# note - stemming is fast and lemmatization is slow . \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a740e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization , unlike Stemming , reduces the inflected words properly ensuring that the root word belongs to the language . \n",
    "# In Lemitization root word is called Lemma . \n",
    "# Alemma (plural lemmas or lemmata) is the canonical form , dictionary form , or citation form of a set of words . \n",
    "\n",
    "# Stemming works on beehalf algorithm  , so it is fast and lemmatization is using wordnet package , so it's slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02fc893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4b3eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a1cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "was                 wa                  \n",
      "and                 and                 \n",
      "at                  at                  \n",
      "same                same                \n",
      ".                   .                   \n",
      "has                 ha                  \n",
      "habbit              habbit              \n",
      "swimming            swimming            \n",
      "playing             playing             \n",
      "hours               hour                \n",
      "the                 the                 \n"
     ]
    }
   ],
   "source": [
    "sentence = 'He was running and eating at the same time . He has bad habbit of swimming after playing long hours in the sun'\n",
    "# punctuation = '?:!.,;'\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    sentence_words.remove(word)\n",
    "    \n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\" , \"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word , wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c39a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
