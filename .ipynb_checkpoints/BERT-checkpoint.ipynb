{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbdoQK9siegG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "9Wpf-sIrihVS",
    "outputId": "d9bec300-bf23-43d0-c1b0-fd75bab2d175"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-042a35b6-7aac-4fb9-8669-f76f7066f128\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-042a35b6-7aac-4fb9-8669-f76f7066f128\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving newspam.csv to newspam (1).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "path_to_file = list(files.upload().keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwPZPUYcm3O7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_file , names = ['Category' , 'Message'] , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2zhD3m81nL05",
    "outputId": "6de58f91-0c86-483e-b6c3-34aedc64daae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-a88c4cc8-cfec-4c6e-96df-ba7020eadba3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>Category</td>\n",
       "      <td>Message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a88c4cc8-cfec-4c6e-96df-ba7020eadba3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-d8721841-ab8e-44a8-ba3e-77d858188be0\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8721841-ab8e-44a8-ba3e-77d858188be0')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-d8721841-ab8e-44a8-ba3e-77d858188be0 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a88c4cc8-cfec-4c6e-96df-ba7020eadba3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a88c4cc8-cfec-4c6e-96df-ba7020eadba3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "NaN  Category                                            Message\n",
       "0.0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1.0       ham                      Ok lar... Joking wif u oni...\n",
       "2.0      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3.0       ham  U dun say so early hor... U c already then say..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNrjeH9enWfr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66lVulaYn7Md"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hsQk3KRn8ge"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PBuBrBgoKTD"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JrvCBaEoOiT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3z-SxUa7o2xo",
    "outputId": "398aa1b1-49ee-4807-91ec-ab0b458214cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-6447a997-88bb-4a6e-b55f-74686330a904\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Message</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6447a997-88bb-4a6e-b55f-74686330a904')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-ee3138d9-4d03-4019-90a4-0a658c8509a0\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee3138d9-4d03-4019-90a4-0a658c8509a0')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-ee3138d9-4d03-4019-90a4-0a658c8509a0 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6447a997-88bb-4a6e-b55f-74686330a904 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6447a997-88bb-4a6e-b55f-74686330a904');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Category                                                                     \n",
       "Category       1      1                                            Message   \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    653  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Category       \n",
       "Category    1  \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EVt13Y8pHo4",
    "outputId": "9e2e6cc1-a0cc-42d1-9369-7cf6445bc762"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham         4825\n",
       "spam         747\n",
       "Category       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAn_GaETpunq",
    "outputId": "20c106e4-d579-4bb4-a798-6d0eabf3816f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15481865284974095"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747/4825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_7p1h9bpy-A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IREWVOCAp4wt"
   },
   "source": [
    "15% spam emails, 85% ham emails: This indicates class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHEnaG9ep5zI",
    "outputId": "b7ce7a03-1d51-4975-86bb-311dcd6ac883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = df[df['Category']=='spam']\n",
    "df_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Csza7v9xp8mC",
    "outputId": "3ebf0d54-98c3-4d56-d6fb-726b55f5f129"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham = df[df['Category']=='ham']\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-IKxEUDp_rW",
    "outputId": "0dc7965c-ccf3-4b7a-acbc-7d5f119f677b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
    "df_ham_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1Dt4C9GqEd3",
    "outputId": "945328cd-6a34-48e9-dc44-a30fe86e9d01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRuHDK7sqSXA",
    "outputId": "3b0a79a0-4e88-4d81-8230-ffd374b9287e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     747\n",
       "spam    747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EAEAmcGfqVR2",
    "outputId": "fe874b9b-f59f-4080-9859-a99c2cc845ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-fb3db493-98de-4043-82da-a5f9ad5dd671\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Then ur physics get a-?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845.0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pls go there today  &amp;lt;#&amp;gt; . I dont want an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299.0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Congrats! 1 year special cinema pass for 2 is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673.0</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have won a Nokia 7250i. This is what you g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb3db493-98de-4043-82da-a5f9ad5dd671')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-b2615845-5344-4bc2-8a56-0f02379ba754\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2615845-5344-4bc2-8a56-0f02379ba754')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-b2615845-5344-4bc2-8a56-0f02379ba754 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fb3db493-98de-4043-82da-a5f9ad5dd671 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fb3db493-98de-4043-82da-a5f9ad5dd671');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Category                                            Message  spam\n",
       "896.0       ham  Hope you are having a good week. Just checking in     0\n",
       "3779.0      ham                            Then ur physics get a-?     0\n",
       "3845.0      ham  Pls go there today  &lt;#&gt; . I dont want an...     0\n",
       "2299.0     spam  Congrats! 1 year special cinema pass for 2 is ...     1\n",
       "3673.0     spam  You have won a Nokia 7250i. This is what you g...     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['spam']=df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MngDvyxUqYd2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUbBHrU_qgCr"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjAYcLsxqxaX",
    "outputId": "a1a0cfdd-08dd-4aa1-9efd-f5bbbd3d90c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1852.0    This is the 2nd time we have tried 2 contact u...\n",
       "5051.0    Tick, tick, tick .... Where are you ? I could ...\n",
       "4875.0    lyricalladie(21/F) is inviting you to be her f...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95zpRlbJq2Ds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gAjzzrIq93d"
   },
   "source": [
    "Now lets import BERT model and get embeding vectors for few sample statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7I30L53Iq-lP"
   },
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgYFPHOIrBy_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjd3UUuCrwcw"
   },
   "source": [
    "This code utilizes TensorFlow Hub to load two pre-trained BERT (Bidirectional Encoder Representations from Transformers) models and their preprocessing module. BERT is a powerful language representation model developed by Google, which is widely used for various natural language processing tasks.\n",
    "\n",
    "\n",
    "\n",
    "(1).\n",
    " hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"): This line loads the pre-trained BERT preprocessing module from TensorFlow Hub. The URL https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3 points to a BERT model trained on English text (uncased version) with the version 3 of the model. The preprocessing module is responsible for tokenizing, padding, and encoding the input text in a format that can be fed into the BERT model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(2).  hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"): This line loads the pre-trained BERT encoder module from TensorFlow Hub. The URL https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4 points to a BERT model with 12 layers (L), 768 hidden units (H), and 12 attention heads (A). This model is also trained on English text (uncased version) and is version 4 of the model. The encoder module is responsible for learning representations of the input text and capturing contextual information.\n",
    "\n",
    "\n",
    "\n",
    "To summarize, this code loads two components of the BERT model:\n",
    "\n",
    "(1). BERT Preprocessing Module: Responsible for tokenizing and preprocessing the input text to make it suitable for BERT model input.\n",
    "\n",
    "(2). BERT Encoder Module: The actual BERT model, which learns to represent text in a meaningful way by capturing contextual information.\n",
    "\n",
    "With these components loaded, you can use them in various NLP tasks such as text classification, sentiment analysis, question answering, etc., by feeding preprocessed text to the encoder and then applying a task-specific layer on top of the encoder's output for the specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgBo1CuSsF8t",
    "outputId": "3880e14e-bdf3-456c-9c34-f237a30bb5a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.8435168 , -0.5132724 , -0.8884571 , ..., -0.7474884 ,\n",
       "        -0.7531473 ,  0.91964483],\n",
       "       [-0.87208354, -0.50543964, -0.94446665, ..., -0.85847497,\n",
       "        -0.7174535 ,  0.88082975]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\",\n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "247oJLNmsKFf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX6kJT24svaL"
   },
   "source": [
    "This code defines a function get_sentence_embeding(sentences) that takes a list of sentences as input, processes them using the BERT model, and returns the embeddings (vectors representing the sentences) for each sentence.\n",
    "\n",
    "Here's a step-by-step explanation of the code:\n",
    "\n",
    "def get_sentence_embeding(sentences):: This line defines a function called get_sentence_embeding that takes a list of sentences as input. The function will return embeddings for these sentences using BERT.\n",
    "\n",
    "preprocessed_text = bert_preprocess(sentences): This line preprocesses the input sentences using the BERT preprocessing module that was loaded earlier. The bert_preprocess function takes care of tokenizing, padding, and encoding the input sentences to prepare them for BERT input. The result of this line is the preprocessed text ready to be fed into the BERT model.\n",
    "\n",
    "return bert_encoder(preprocessed_text)['pooled_output']: This line passes the preprocessed text to the BERT encoder module that was loaded earlier. The bert_encoder function computes the embeddings (vectors representing the sentences) for each sentence in the preprocessed text.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bert_encoder(preprocessed_text) applies the BERT model to the preprocessed text. The output is a dictionary containing various keys, and one of them is 'pooled_output'. 'pooled_output' represents the embedding of the entire sentence after processing through the BERT model. It captures the contextual information of the sentence and is commonly used for tasks like sentence-level classification.\n",
    "\n",
    "return bert_encoder(preprocessed_text)['pooled_output'] returns the 'pooled_output' embeddings as the final output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnvOvWzvs3Km"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExtEWWsWtLiO"
   },
   "source": [
    "Get embeding vectors for few sample words. Compare them using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPYMKNHltQuh"
   },
   "outputs": [],
   "source": [
    "e = get_sentence_embeding([\n",
    "    \"banana\",\n",
    "    \"grapes\",\n",
    "    \"mango\",\n",
    "    \"jeff bezos\",\n",
    "    \"elon musk\",\n",
    "    \"bill gates\"\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0E9BvO5itTm-",
    "outputId": "8c063182-4fd8-4b07-870d-528347d611e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9911088]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([e[0]],[e[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAbvlUXEtYAZ",
    "outputId": "dad4abe2-72b3-4772-c4e3-24c83e589607"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9850745]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[1]],[e[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7TqnXipt7w4",
    "outputId": "7538c6bf-72f0-4fce-c8fd-94c28bfd1068"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84945345]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[2]],[e[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnMNF4a3t-Il",
    "outputId": "e5369693-6aad-4fc0-fd45-acf0e295ca9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9872036]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[3]],[e[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XfCEIOluCxY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeV9gG1WuMts"
   },
   "source": [
    "cosine_similarity(v1, v2): This is a function that calculates the cosine similarity between two vectors v1 and v2. The cosine similarity formula is as follows:\n",
    "\n",
    "cosine_similarity(v1, v2) = dot_product(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "(1). dot_product(v1, v2) is the dot product of vectors v1 and v2.\n",
    "\n",
    "\n",
    "(2). norm(v1) is the Euclidean norm (magnitude) of vector v1.\n",
    "\n",
    "\n",
    "(3). norm(v2) is the Euclidean norm (magnitude) of vector v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuHGPeH9uhq_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9gKv5zGuvfY"
   },
   "source": [
    "Build Model\n",
    "There are two types of models you can build in tensorflow.\n",
    "\n",
    "(1) Sequential (2) Functional\n",
    "\n",
    "\n",
    "In TensorFlow, there are two main ways to create models: the Sequential API and the Functional API. Both approaches allow you to build and train neural networks, but they have some differences in how you define and connect layers.\n",
    "\n",
    "(1). Sequential API:\n",
    "\n",
    "\n",
    "The Sequential API is a simple and straightforward way to create a linear stack of layers, where each layer has one input tensor and one output tensor. It is suitable for building feedforward neural networks or other networks with a single input and a single output. However, it may not be suitable for models with multiple inputs, multiple outputs, or complex architectures.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8vb5iiTviSr"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Creating a sequential model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Summary of the model\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZL6_mcSvqoF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOJSOXJyvvIO"
   },
   "source": [
    "(2).  Functional API:\n",
    "\n",
    "\n",
    "The Functional API provides more flexibility and allows you to create more complex models with multiple inputs, multiple outputs, shared layers, or skip connections. It is particularly useful for building models with a directed acyclic graph (DAG) structure. The Functional API allows you to explicitly define the connections between layers, making it easier to create intricate architectures.\n",
    "\n",
    "Example :\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(input_dim,))\n",
    "\n",
    "# Hidden layers\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rN052IEGv7nN"
   },
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6oE9_RIwI-3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFm-WhsgwkMh"
   },
   "source": [
    "This code defines a neural network model that combines BERT (Bidirectional Encoder Representations from Transformers) layers with additional neural network layers for a specific task, such as text classification. It uses TensorFlow to create the model using the Functional API.\n",
    "\n",
    "Here's a step-by-step explanation of the code:\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text'): This line creates an input layer called text_input, which will receive text data as input. The shape=() indicates that the input will be a single string (i.e., one text sample), and dtype=tf.string specifies that the input data type will be a string.\n",
    "\n",
    "preprocessed_text = bert_preprocess(text_input): This line preprocesses the text data using the BERT preprocessing layer that you loaded earlier using bert_preprocess.\n",
    "\n",
    "outputs = bert_encoder(preprocessed_text): This line feeds the preprocessed text data through the BERT encoder layer, which you loaded earlier using bert_encoder. The outputs will be a dictionary containing various keys, one of which is 'pooled_output'.\n",
    "\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output']): This line applies a dropout layer to the 'pooled_output' obtained from BERT. Dropout is a regularization technique that randomly sets a fraction of input units to zero during training to prevent overfitting.\n",
    "\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l): This line adds a Dense (fully connected) layer with one output unit and a sigmoid activation function. The sigmoid activation function is commonly used for binary classification tasks, where the output value will be in the range of [0, 1], representing the probability of the positive class.\n",
    "\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[l]): This line constructs the final model by specifying the input (text_input) and output (l) layers. The model takes a single text input and produces a single output representing the probability of the positive class for binary classification.\n",
    "\n",
    "The final model combines the BERT layers for text encoding with additional layers for classification. This approach is common in transfer learning scenarios, where the pretrained BERT model is used as a feature extractor for text data and is then followed by task-specific layers to perform a specific NLP task such as sentiment analysis or text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuCTJSpgwkto",
    "outputId": "4d4b7981-7071-4137-8517-d3d1334da258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " text (InputLayer)           [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)    {'input_type_ids': (None,    0         ['text[0][0]']                \n",
      "                             128),                                                                \n",
      "                              'input_mask': (None, 128)                                           \n",
      "                             , 'input_word_ids': (None,                                           \n",
      "                              128)}                                                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)  {'pooled_output': (None, 7   1094822   ['keras_layer[0][0]',         \n",
      "                             68),                         41         'keras_layer[0][1]',         \n",
      "                              'default': (None, 768),                'keras_layer[0][2]']         \n",
      "                              'sequence_output': (None,                                           \n",
      "                              128, 768),                                                          \n",
      "                              'encoder_outputs': [(None                                           \n",
      "                             , 128, 768),                                                         \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768),                                                   \n",
      "                              (None, 128, 768)]}                                                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1)                    769       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109483010 (417.64 MB)\n",
      "Trainable params: 769 (3.00 KB)\n",
      "Non-trainable params: 109482241 (417.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFdBs58XwrR0",
    "outputId": "2ae49697-a44c-4529-b0b8-97a6fe2f8690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNSFwmQDxCJR"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kR6vlBJxGjE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cn2bRp3xKda"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrA4WKlJxLww",
    "outputId": "425015f2-ffd7-487e-ec74-de78079ef36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 683s 19s/step - loss: 0.6228 - accuracy: 0.6679 - precision: 0.6703 - recall: 0.6607\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 636s 18s/step - loss: 0.5017 - accuracy: 0.8295 - precision: 0.8243 - recall: 0.8375\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 593s 17s/step - loss: 0.4470 - accuracy: 0.8429 - precision: 0.8189 - recall: 0.8804\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 595s 17s/step - loss: 0.4000 - accuracy: 0.8652 - precision: 0.8658 - recall: 0.8643\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 587s 17s/step - loss: 0.3910 - accuracy: 0.8482 - precision: 0.8218 - recall: 0.8893\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 585s 17s/step - loss: 0.3484 - accuracy: 0.8848 - precision: 0.8801 - recall: 0.8911\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 585s 17s/step - loss: 0.3311 - accuracy: 0.8848 - precision: 0.8659 - recall: 0.9107\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 584s 17s/step - loss: 0.3140 - accuracy: 0.8920 - precision: 0.8858 - recall: 0.9000\n",
      "Epoch 9/10\n",
      "32/35 [==========================>...] - ETA: 50s - loss: 0.3127 - accuracy: 0.9004 - precision: 0.8928 - recall: 0.9069 "
     ]
    }
   ],
   "source": [
    "model.fit(X_train , y_train , epochs = 4)  #TAKE 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKWDjIsPxRR-"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXLteTK2xbAg"
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rFTfO33xbkh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRrYPOsHx28u"
   },
   "source": [
    "y_predicted.flatten() is used to convert a multi-dimensional array (in this case, a 2D array) into a 1D array. The flatten() function in numpy is used for this purpose.\n",
    "\n",
    "flatten() returns a copy of the array, so the original y_predicted array remains unchanged unless you reassign it to the result of y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMRvpRwJxbnJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJb4Fl6Fxbqi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeU7GkeSyQzT"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40vl_GA5yQ1v"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKp0QcGQyQ32"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPnDRBOLzD3v"
   },
   "source": [
    "Precision, Recall, F1-score, Support, Accuracy, Macro avg, and Weighted avg are common metrics used in binary and multiclass classification tasks to evaluate the performance of machine learning models. Let's explain each of them:\n",
    "\n",
    "Precision:\n",
    "Precision is a metric that measures the accuracy of positive predictions made by the model. It is calculated as the ratio of true positive (TP) predictions to the total number of positive predictions (true positives + false positives).\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate):\n",
    "Recall is a metric that measures the ability of the model to identify all the positive instances correctly. It is calculated as the ratio of true positive (TP) predictions to the total number of actual positive instances (true positives + false negatives).\n",
    "\n",
    "F1-score:\n",
    "The F1-score is the harmonic mean of precision and recall. It provides a single score that balances both precision and recall. It is particularly useful when you want to consider both false positives and false negatives equally important.\n",
    "\n",
    "Support:\n",
    "Support represents the number of occurrences of each class in the true labels. It is useful in multiclass classification, where it gives an indication of how well the model performs for each class based on its representation in the data.\n",
    "\n",
    "Accuracy:\n",
    "Accuracy measures the overall correctness of the model's predictions. It is calculated as the ratio of the total number of correct predictions (true positives + true negatives) to the total number of instances in the dataset.\n",
    "\n",
    "Macro avg:\n",
    "Macro average calculates the average of the metrics (precision, recall, F1-score) for each class independently and then takes the unweighted mean of these values. It gives equal importance to each class, regardless of class imbalance.\n",
    "\n",
    "Weighted avg:\n",
    "Weighted average calculates the average of the metrics (precision, recall, F1-score) for each class independently and then takes the weighted mean of these values based on the class support. It gives more importance to the metrics of the larger classes.\n",
    "\n",
    "In summary:\n",
    "\n",
    "(1). Precision focuses on the accuracy of positive predictions.\n",
    "\n",
    "(2). Recall focuses on the ability to identify positive instances correctly.\n",
    "\n",
    "(3). F1-score balances precision and recall.\n",
    "\n",
    "(4). Support shows the number of instances for each class in the true labels.\n",
    "\n",
    "(5). Accuracy measures overall correctness.\n",
    "\n",
    "(6). Macro avg treats each class equally in the average.\n",
    "\n",
    "(7). Weighted avg considers class imbalance in the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3fHm1-cyQ6s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKW36kIfzswP"
   },
   "source": [
    "Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTARhSZAyQ-N"
   },
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    'Enter a chance to win $5000, hurry up, offer valid until march 31, 2021',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p p3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "model.predict(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNk5pxz9zxy5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpDrHvYC03TT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0hUq7O-03WD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G4DZwpX03Yq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGL-mLBr03bK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Doo5Gilh03eZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZOxPWMT0_20"
   },
   "source": [
    "What is BERT ?\n",
    "\n",
    "BERT, which stands for Bidirectional Encoder Representations from Transformers, is a powerful language representation model developed by Google. It has revolutionized the field of Natural Language Processing (NLP) by significantly improving the way machines understand and generate human language. Here's a comprehensive explanation of BERT:\n",
    "\n",
    "Pre-training and Transfer Learning:\n",
    "BERT is a pre-trained model, which means it has been trained on a massive amount of raw text from the internet. The training process involves predicting missing words in a sentence, where BERT is trained to understand the context of each word by considering the entire sentence bidirectionally. This pre-training process captures rich, contextualized representations of words and sentences, allowing BERT to learn intricate language patterns.\n",
    "\n",
    "Bidirectional Context:\n",
    "Unlike traditional language models (e.g., GPT-2), BERT reads the entire sentence bidirectionally. It uses a transformer-based architecture, where each word in the sentence is contextualized based on both the words that come before and after it. This bidirectional context enables BERT to capture deeper semantic relationships between words, making it highly effective in various NLP tasks.\n",
    "\n",
    "Masked Language Model (MLM):\n",
    "One of the pre-training tasks in BERT involves randomly masking (hiding) some words in a sentence and training the model to predict these masked words. This task forces BERT to learn representations that can understand the context of a word from its surrounding words, even if the word itself is missing.\n",
    "\n",
    "Next Sentence Prediction (NSP):\n",
    "Another pre-training task in BERT is Next Sentence Prediction, where the model is trained to predict if a pair of sentences appear consecutively in the original text. This task helps BERT understand the relationships between different sentences and is useful for tasks like question answering or sentiment analysis.\n",
    "\n",
    "Fine-Tuning:\n",
    "After pre-training, BERT can be fine-tuned on specific downstream NLP tasks. During fine-tuning, BERT is further trained on labeled data for tasks like text classification, named entity recognition, question answering, etc. Fine-tuning adapts the generic language understanding capabilities of BERT to the specifics of the task at hand.\n",
    "\n",
    "Why Use BERT in NLP:\n",
    "\n",
    "BERT excels at understanding the context of words, which is essential for NLP tasks.\n",
    "It captures rich semantics and syntactic information from text data.\n",
    "BERT's pre-training allows it to generalize well to various downstream tasks with minimal task-specific training data.\n",
    "By fine-tuning BERT on specific tasks, we can achieve state-of-the-art performance on a wide range of NLP tasks with a single, powerful model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
